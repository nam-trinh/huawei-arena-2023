{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cee5cb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (2.0.1)\n",
      "Requirement already satisfied: transformers in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (4.32.1)\n",
      "Requirement already satisfied: accelerate in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (0.23.0)\n",
      "Requirement already satisfied: bitsandbytes in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (0.41.1)\n",
      "Collecting scipy\n",
      "  Obtaining dependency information for scipy from https://files.pythonhosted.org/packages/a3/d3/f88285098505c8e5d141678a24bb9620d902c683f11edc1eb9532b02624e/scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (59 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (68.0.0)\n",
      "Requirement already satisfied: wheel in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: cmake in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from triton==2.0.0->torch) (3.27.4.1)\n",
      "Requirement already satisfied: lit in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from triton==2.0.0->torch) (16.0.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: psutil in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: fsspec in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.5/36.5 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: scipy\n",
      "Successfully installed scipy-1.11.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torch transformers accelerate bitsandbytes scipy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba01ef1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0df13b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61c60f9",
   "metadata": {},
   "source": [
    "# Load the model\n",
    "\n",
    "Set parameter load_in_4bit=True for a model size of 12GB, otherwise the model will be too big. \n",
    "If you work on A100 machine, parameter torch_dtype=torch.bfloat16 can be set to True instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de47a1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fa8802870a84041a4b80df5b58de785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62495a6166f34972b1b410a2a674040c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"defog/sqlcoder\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True,\n",
    "    # torch_dtype=torch.bfloat16,\n",
    "    # load_in_8bit=True,\n",
    "    load_in_4bit=True,\n",
    "    device_map=\"auto\",\n",
    "    use_cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140c3bfe",
   "metadata": {},
   "source": [
    "# Prompt Engineering Here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "532d7838",
   "metadata": {},
   "outputs": [],
   "source": [
    "question =  \"\"\"\n",
    "            What product has the biggest fall in sales in 2022 compared to 2021? \n",
    "            Give me the product name, the sales amount in both years, and the difference.\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef9aa8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"### Instructions:\n",
    "Your task is to convert a question into a SQL query, given a Postgres database schema.\n",
    "Adhere to these rules:\n",
    "- **Deliberately go through the question and database schema word by word** to appropriately answer the question\n",
    "- **Use Table Aliases** to prevent ambiguity. For example, `SELECT table1.col1, table2.col1 FROM table1 JOIN table2 ON table1.id = table2.id`.\n",
    "- When creating a ratio, always cast the numerator as float\n",
    "\n",
    "### Input:\n",
    "Generate a SQL query that answers the question `{question}`.\n",
    "This query will run on a database whose schema is represented in this string:\n",
    "CREATE TABLE products (\n",
    "  product_id INTEGER PRIMARY KEY, -- Unique ID for each product\n",
    "  name VARCHAR(50), -- Name of the product\n",
    "  price DECIMAL(10,2), -- Price of each unit of the product\n",
    "  quantity INTEGER  -- Current quantity in stock\n",
    ");\n",
    "\n",
    "CREATE TABLE customers (\n",
    "   customer_id INTEGER PRIMARY KEY, -- Unique ID for each customer\n",
    "   name VARCHAR(50), -- Name of the customer\n",
    "   address VARCHAR(100) -- Mailing address of the customer\n",
    ");\n",
    "\n",
    "CREATE TABLE salespeople (\n",
    "  salesperson_id INTEGER PRIMARY KEY, -- Unique ID for each salesperson\n",
    "  name VARCHAR(50), -- Name of the salesperson\n",
    "  region VARCHAR(50) -- Geographic sales region\n",
    ");\n",
    "\n",
    "CREATE TABLE sales (\n",
    "  sale_id INTEGER PRIMARY KEY, -- Unique ID for each sale\n",
    "  product_id INTEGER, -- ID of product sold\n",
    "  customer_id INTEGER,  -- ID of customer who made purchase\n",
    "  salesperson_id INTEGER, -- ID of salesperson who made the sale\n",
    "  sale_date DATE, -- Date the sale occurred\n",
    "  quantity INTEGER -- Quantity of product sold\n",
    ");\n",
    "\n",
    "CREATE TABLE product_suppliers (\n",
    "  supplier_id INTEGER PRIMARY KEY, -- Unique ID for each supplier\n",
    "  product_id INTEGER, -- Product ID supplied\n",
    "  supply_price DECIMAL(10,2) -- Unit price charged by supplier\n",
    ");\n",
    "\n",
    "-- sales.product_id can be joined with products.product_id\n",
    "-- sales.customer_id can be joined with customers.customer_id\n",
    "-- sales.salesperson_id can be joined with salespeople.salesperson_id\n",
    "-- product_suppliers.product_id can be joined with products.product_id\n",
    "\n",
    "### Response:\n",
    "Based on your instructions, here is the SQL query I have generated to answer the question `{question}`:\n",
    "```sql\n",
    "\"\"\".format(question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67c5e73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_token_id = tokenizer.convert_tokens_to_ids([\"```\"])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd614c99",
   "metadata": {},
   "source": [
    "# Generate an SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62298fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/namtrinh/anaconda3/envs/huawei_arena/lib/python3.9/site-packages/bitsandbytes/nn/modules.py:224: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(f'Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.')\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "generated_ids = model.generate(\n",
    "    **inputs,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=eos_token_id,\n",
    "    pad_token_id=eos_token_id,\n",
    "    max_new_tokens=400,\n",
    "    do_sample=False,\n",
    "    num_beams=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4f87c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fa1a1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()\n",
    "# empty cache so that you do generate more results w/o memory crashing\n",
    "# particularly important on Colab – memory management is much more straightforward\n",
    "# when running on an inference service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd8644bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH sales_2021 AS (\n",
      "  SELECT sales.product_id,\n",
      "         sum(sales.quantity) AS sales_2021\n",
      "  FROM   sales\n",
      "  WHERE  sales.sale_date >= '2021-01-01'\n",
      "     AND sales.sale_date <= '2021-12-31'\n",
      "  GROUP BY sales.product_id\n",
      "), sales_2022 AS (\n",
      "  SELECT sales.product_id,\n",
      "         sum(sales.quantity) AS sales_2022\n",
      "  FROM   sales\n",
      "  WHERE  sales.sale_date >= '2022-01-01'\n",
      "     AND sales.sale_date <= '2022-12-31'\n",
      "  GROUP BY sales.product_id\n",
      ")\n",
      "SELECT products.name,\n",
      "       sales_2021.sales_2021,\n",
      "       sales_2022.sales_2022,\n",
      "       sales_2022.sales_2022 - sales_2021.sales_2021 AS difference\n",
      "FROM   products\n",
      "    LEFT JOIN sales_2021 ON products.product_id = sales_2021.product_id\n",
      "    LEFT JOIN sales_2022 ON products.product_id = sales_2022.product_id\n",
      "ORDER BY difference DESC NULLS LAST;\n"
     ]
    }
   ],
   "source": [
    "print(outputs[0].split(\"```sql\")[-1].split(\"```\")[0].split(\";\")[0].strip() + \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa00768",
   "metadata": {},
   "source": [
    "# Main functions required by the Huawei organisers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a6d5ca",
   "metadata": {},
   "source": [
    "### Function to connect to database and return a connection object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfcd5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "def connect_fun(database_name: str) -> sqlite3.Connection:\n",
    "    \"\"\"\n",
    "    Connect to an SQLite database and return a connection object.\n",
    "\n",
    "    Parameters:\n",
    "        database_name (str): The name of the SQLite database file to connect to.\n",
    "\n",
    "    Returns:\n",
    "        sqlite3.Connection or None: A connection object if the connection is successful,\n",
    "        or None if there is an error.\n",
    "\n",
    "    Example usage:\n",
    "        db_name = 'your_database_name.db'\n",
    "        connection = connect_fun(db_name)\n",
    "        \n",
    "        if connection:\n",
    "            print(f\"Connected to {db_name}\")\n",
    "            # You can now use 'connection' to interact with the database.\n",
    "        else:\n",
    "            print(\"Connection failed.\")\n",
    "    \"\"\"\n",
    "    try:\n",
    "        connection = sqlite3.connect(database_name)\n",
    "        return connection\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Error connecting to the database: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e48828",
   "metadata": {},
   "source": [
    "### Function to query a database and return an answer based on the context return from the SQL query\n",
    "\n",
    "Example: \n",
    "\n",
    "    Question: What is the months with the highest sales in the year? \n",
    "    Answer:   The highest sales happened in November, December and January \n",
    "    Prompt flow: \n",
    "        Question (str) -> **LLM SQL query model** -> SQL query -> returned schema -> **LLM to generate answer with context based on returned schema**\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ae132cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import sqlite3\n",
    "\n",
    "def query_fun(question: str, tables_hints: List[str], conn: sqlite3.Connection) -> str:\n",
    "    \"\"\"\n",
    "    Generate an answer to a question based on an SQLite database and question context.\n",
    "\n",
    "    Parameters:\n",
    "        question (str): The user's question.\n",
    "        tables_hints (List[str]): List of table names to consider in the query.\n",
    "        conn (sqlite3.Connection): A connection to the SQLite database.\n",
    "\n",
    "    Returns:\n",
    "        str: The answer to the question.\n",
    "\n",
    "    Example usage:\n",
    "        question = \"How many customers are there in the database?\"\n",
    "        table_hints = [\"customers\"]\n",
    "        connection = sqlite3.connect(\"your_database.db\")\n",
    "        answer = query_fun(question, table_hints, connection)\n",
    "        print(answer)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Step 1: Generate an SQL query based on the question and table hints.\n",
    "        sql_query = generate_sql_query(question, tables_hints)\n",
    "\n",
    "        # Step 2: Execute the SQL query and fetch the results.\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(sql_query)\n",
    "\n",
    "        # Step 3: Obtain the schema information (column names) from the cursor description.\n",
    "        schema = [desc[0] for desc in cursor.description]\n",
    "\n",
    "        # Step 4: Process the query result and generate an answer with context using LLM.\n",
    "        answer = generate_answer_with_context(question, schema)\n",
    "\n",
    "        return answer\n",
    "\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"SQLite Error: {e}\")\n",
    "        return \"An error occurred while processing the query.\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"An error occurred.\"\n",
    "\n",
    "def generate_sql_query(question: str, tables_hints: List[str]) -> str:\n",
    "    # Implement logic to generate an SQL query based on the question and table hints.\n",
    "    # Replace the \"pass\" with a calling function to LLM\n",
    "    \n",
    "    # Handle the case when table hints are empty or invalid.\n",
    "    if not tables_hints:\n",
    "        # Default behavior: Query all tables\n",
    "        return \"SELECT * FROM sqlite_master WHERE type='table'\"\n",
    "    \n",
    "    # Handle the case when table hints are provided.\n",
    "    # Example: \"SELECT COUNT(*) FROM customers\"\n",
    "    pass\n",
    "\n",
    "def generate_answer_with_context(question: str, schema: List[str]) -> str:\n",
    "    # Implement logic to generate an answer with context based on the question and schema.\n",
    "    # You can use a language model (LLM) to generate the answer, incorporating schema information.\n",
    "    # Example: \"There are 100 customers in the database.\"\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d13c4a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
