{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7f8c3f6",
   "metadata": {},
   "source": [
    "# Notebook to test similarity between columns and question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dca9413",
   "metadata": {},
   "source": [
    "### Compute similarities between question and table info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd53819a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/namtrinh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/namtrinh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    # Remove special characters and spaces\n",
    "    text = re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
    "    # Remove extra spaces\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "def compute_similarity(question, table_info):\n",
    "    # Load a pre-trained sentence transformer model (e.g., 'bert-base-nli-stsb-mean-tokens')\n",
    "    model = SentenceTransformer('all-MiniLM-L12-v2')\n",
    "\n",
    "    # Tokenize the question and remove stopwords\n",
    "    question_tokens = set(word_tokenize(question.lower()))\n",
    "    stopwords_set = set(stopwords.words(\"english\"))\n",
    "    question_tokens -= stopwords_set\n",
    "\n",
    "    # Create a similarity dictionary to store similarity scores for each column\n",
    "    column_similarities = {}\n",
    "\n",
    "    for table_name, columns in table_info.items():\n",
    "        # Remove special characters from table name\n",
    "        # table_name = remove_special_characters(table_name)\n",
    "\n",
    "        for column in columns:\n",
    "            # Remove special characters from column name\n",
    "            column_cleaned = remove_special_characters(column)\n",
    "\n",
    "            # Compute embeddings for the cleaned column name\n",
    "            column_embedding = model.encode(column_cleaned, convert_to_tensor=True)\n",
    "\n",
    "            # Compute cosine similarity\n",
    "            similarity_score = util.pytorch_cos_sim(\n",
    "                model.encode(' '.join(question_tokens), convert_to_tensor=True),\n",
    "                column_embedding\n",
    "            ).item()\n",
    "\n",
    "            # Store the similarity score with the original column name\n",
    "            column_similarities[f'{table_name}.{column}'] = similarity_score\n",
    "\n",
    "    # Sort the column similarities by descending similarity score\n",
    "    sorted_similarities = sorted(column_similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return sorted_similarities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7d5e1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30940142273902893\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L12-v2')\n",
    "similarity_score = util.pytorch_cos_sim(\n",
    "    model.encode(\"what is id with name jui and age less than 25\", convert_to_tensor=True),\n",
    "    model.encode(\"name\", convert_to_tensor=True)\n",
    ").item()\n",
    "\n",
    "print(similarity_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1062eb",
   "metadata": {},
   "source": [
    "### Filter the table based on the similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6eda604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_columns(table_info, similarities, threshold):\n",
    "    # Create a new table_info dictionary to store filtered columns\n",
    "    filtered_table_info = {}\n",
    "\n",
    "    for table_name, columns in table_info.items():\n",
    "        filtered_columns = []\n",
    "        for column, similarity in similarities:\n",
    "            # Check if the column belongs to the current table\n",
    "            if column.startswith(table_name):\n",
    "                # Keep the column if similarity is above the threshold\n",
    "                if similarity >= threshold:\n",
    "                    filtered_columns.append(column)\n",
    "\n",
    "        # Only add the table to the filtered_table_info if it has at least one matching column\n",
    "        if filtered_columns:\n",
    "            filtered_table_info[table_name] = [col.split('.')[-1] for col in filtered_columns]\n",
    "\n",
    "    return filtered_table_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a5fd6a",
   "metadata": {},
   "source": [
    "### Test the two functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23e334fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_inventory.Product ID: 0.6935524344444275\n",
      "customer_orders.Product ID: 0.6935524344444275\n",
      "supplier_info.Product ID: 0.6935524344444275\n",
      "product_inventory.Price: 0.601889431476593\n",
      "supplier_info.Price: 0.601889431476593\n",
      "customer_orders.Order ID: 0.5161583423614502\n",
      "supplier_info.Supplier ID: 0.47025567293167114\n",
      "product_inventory.Product Name: 0.4453805088996887\n",
      "product_inventory.Quantity Available: 0.39232760667800903\n",
      "employee_info.Employee ID: 0.36830848455429077\n",
      "customer_orders.Customer Name: 0.34300094842910767\n",
      "customer_orders.Quantity Ordered: 0.3100193738937378\n",
      "supplier_info.Supplier Name: 0.23508597910404205\n",
      "customer_orders.Order Date: 0.1878075897693634\n",
      "employee_info.Department: 0.18518131971359253\n",
      "supplier_info.Availability: 0.18446308374404907\n",
      "employee_info.First Name: 0.16425180435180664\n",
      "employee_info.Salary: 0.1637563407421112\n",
      "employee_info.Last Name: 0.1349141150712967\n",
      "product_inventory.Category: 0.11724652349948883\n",
      "\n",
      "Filtered table info:  {'product_inventory': ['Product ID', 'Price'], 'customer_orders': ['Product ID', 'Order ID'], 'supplier_info': ['Product ID', 'Price']}\n"
     ]
    }
   ],
   "source": [
    "# Example table information with special characters and spaces\n",
    "table_info = {\n",
    "    'product_inventory': ['Product ID', 'Product Name', 'Category', 'Price', 'Quantity Available'],\n",
    "    'employee_info': ['Employee ID', 'First Name', 'Last Name', 'Department', 'Salary'],\n",
    "    'customer_orders': ['Order ID', 'Customer Name', 'Product ID', 'Quantity Ordered', 'Order Date'],\n",
    "    'supplier_info': ['Supplier ID', 'Supplier Name', 'Product ID', 'Price', 'Availability'],\n",
    "}\n",
    "\n",
    "# Example question \n",
    "question = \"What is the price of Product ID 12345?\"\n",
    "\n",
    "# Compute similarities for the question\n",
    "similarities = compute_similarity(question, table_info)\n",
    "\n",
    "for column, similarity in similarities:\n",
    "    print(f'{column}: {similarity}')\n",
    "    \n",
    "# Set the threshold for filtering columns\n",
    "threshold = 0.5\n",
    "\n",
    "# Filter columns by threshold and print the filtered table_info\n",
    "filtered_table_info = filter_columns(table_info, similarities, threshold)\n",
    "print('\\nFiltered table info: ', filtered_table_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f834a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"juierror/flan-t5-text2sql-with-schema-v2\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"juierror/flan-t5-text2sql-with-schema-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06c322e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('people_age.age', 0.5091162323951721), ('people_age.people_id', 0.27685049176216125), ('people_name.name', 0.17837558686733246), ('people_name.id', 0.0970044806599617)]\n",
      "Filtered table info put to the prompt:  {'people_age': ['age']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/namtrinh/.local/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:377: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `10` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT count(*) FROM people_age WHERE name = 'jui' AND age < 25\n",
      "[('people_name.age', 0.4023008644580841), ('people_name.id', 0.32995232939720154), ('people_name.name', 0.2714892625808716)]\n",
      "Filtered table info put to the prompt:  {'people_name': ['age']}\n",
      "SELECT id FROM people_name WHERE name = 'jui' AND age < 25\n"
     ]
    }
   ],
   "source": [
    "def get_prompt(tables, question):\n",
    "    prompt = f\"\"\"convert question and table into SQL query. tables: {tables}. question: {question}\"\"\"\n",
    "    return prompt\n",
    "\n",
    "def prepare_input(question: str, tables: Dict[str, List[str]]):\n",
    "    tables = [f\"\"\"{table_name}({\",\".join(tables[table_name])})\"\"\" for table_name in tables]\n",
    "    tables = \", \".join(tables)\n",
    "    prompt = get_prompt(tables, question)\n",
    "    input_ids = tokenizer(prompt, max_length=512, return_tensors=\"pt\").input_ids\n",
    "    return input_ids\n",
    "\n",
    "def inference(question: str, tables: Dict[str, List[str]]) -> str:\n",
    "    similarities = compute_similarity(question, tables)\n",
    "    filtered_table_info = filter_columns(tables, similarities, threshold=0.4)\n",
    "    print(similarities)\n",
    "    print('Filtered table info put to the prompt: ', str(filtered_table_info))\n",
    "    \n",
    "    input_data = prepare_input(question=question, tables=filtered_table_info)\n",
    "    input_data = input_data.to(model.device)\n",
    "    outputs = model.generate(inputs=input_data, num_beams=10, top_k=10, max_length=512)\n",
    "    result = tokenizer.decode(token_ids=outputs[0], skip_special_tokens=True)\n",
    "    return result\n",
    "\n",
    "print(inference(\"how many people with name jui and age less than 25\", {\n",
    "    \"people_name\": [\"id\", \"name\"],\n",
    "    \"people_age\": [\"people_id\", \"age\"]\n",
    "}))\n",
    "\n",
    "print(inference(\"what is id with name jui and age less than 25\", {\n",
    "    \"people_name\": [\"id\", \"name\", \"age\"]\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f2f7a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSeq2SeqLM\n",
    "from infection import prompt as sprompt\n",
    "from infection.databases import SQL3Database\n",
    "from infection.trustworthiness.hallucination import fix_sql_hallucination\n",
    "import sqlite3\n",
    "import torch \n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d40affe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'NumbersStation/nsql-350M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6616a29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "model.eval()\n",
    "def connect_func(database_name: str, database_type: str = 'sqlite3'):\n",
    "    try:\n",
    "        connection = SQL3Database(database_name)\n",
    "        return connection\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Error connecting to the database: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1eae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = connect_func('../data/example-data/example-covid-vaccinations.sqlite3')\n",
    "schemas = connection.format_schemas(add_examples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98172c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE covid_vaccinations (\n",
      " \tSTATISTIC_CODE varchar(10),\n",
      "\tStatistic_Label varchar(30),\n",
      "\tTLIST(M1) INT,\n",
      "\tMonth varchar(20),\n",
      "\tC03898V04649 varchar(30),\n",
      "\tLocal Electoral Area varchar(50),\n",
      "\tC02076V03371 varchar(10),\n",
      "\tAge Group varchar(30),\n",
      "\tUNIT varchar(10),\n",
      "\tVALUE float,\n",
      ");\n",
      "SELECT * FROM covid_vaccinations LIMIT 1;\n",
      "| STATISTIC_CODE   | Statistic_Label   |   TLIST(M1) | Month        | C03898V04649                         | Local Electoral Area                 |   C02076V03371 | Age Group    | UNIT   |   VALUE |\n",
      "|------------------|-------------------|-------------|--------------|--------------------------------------|--------------------------------------|----------------|--------------|--------|---------|\n",
      "| CDC45C01         | Fully Vaccinated  |      202101 | 2021 January | 2ae19629-3eff-13a3-e055-000000000001 | Borris-In-Ossory-Mountmellick, Laois |            247 | 5 - 11 years | %      |       0 |\n",
      "\n",
      "\n",
      "**Using valid SQLite, answer the following questions for the tables provided above**.\n",
      "-- What's the statistic code used for fully vaccinated?\n",
      "```sql\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "question = \"What's the statistic code used for fully vaccinated?\"\n",
    "# query = sprompt.SQL_QUERY_PROMPT_TEMPLATE.format(question=question, db_schema=schemas, tables_hints=None)\n",
    "prompt = \"\"\"\n",
    "{schemas}\n",
    "**Using valid SQLite, answer the following questions for the tables provided above**.\n",
    "-- {question}\n",
    "```sql\n",
    "\"\"\"\n",
    "query = prompt.format(schemas=schemas, question=question)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93b0a893",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/namtrinh/.local/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT STATISTIC_CODE FROM covid_vaccinations WHERE Statistic_Label = 'Fully Vaccinated';\n"
     ]
    }
   ],
   "source": [
    "eos_token_id = tokenizer.convert_tokens_to_ids([\"```\"])[0]\n",
    "inputs = tokenizer(query, return_tensors=\"pt\")\n",
    "\n",
    "generated_ids = model.generate(\n",
    "            **inputs,\n",
    "            num_return_sequences=1,\n",
    "            eos_token_id=eos_token_id,\n",
    "            pad_token_id=eos_token_id,\n",
    "            max_new_tokens=500,\n",
    "            do_sample=False,\n",
    "            num_beams=1\n",
    "        )\n",
    "        \n",
    "outputs = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "outputs = outputs[0].split(\"```sql\")[-1].split(\"```\")[0].split(\";\")[0].strip() + \";\"\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b502b9c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
