{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f291243c",
   "metadata": {},
   "source": [
    "# Notebook to test similarity between columns and question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc185298",
   "metadata": {},
   "source": [
    "### Compute similarities between question and table info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63f6abba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/namtrinh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/namtrinh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    # Remove special characters and spaces\n",
    "    text = re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
    "    # Remove extra spaces\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "def compute_similarity(question, table_info):\n",
    "    # Load a pre-trained sentence transformer model (e.g., 'bert-base-nli-stsb-mean-tokens')\n",
    "    model = SentenceTransformer('all-MiniLM-L12-v2')\n",
    "\n",
    "    # Tokenize the question and remove stopwords\n",
    "    question_tokens = set(word_tokenize(question.lower()))\n",
    "    stopwords_set = set(stopwords.words(\"english\"))\n",
    "    question_tokens -= stopwords_set\n",
    "\n",
    "    # Create a similarity dictionary to store similarity scores for each column\n",
    "    column_similarities = {}\n",
    "\n",
    "    for table_name, columns in table_info.items():\n",
    "        # Remove special characters from table name\n",
    "        # table_name = remove_special_characters(table_name)\n",
    "\n",
    "        for column in columns:\n",
    "            # Remove special characters from column name\n",
    "            column_cleaned = remove_special_characters(column)\n",
    "\n",
    "            # Compute embeddings for the cleaned column name\n",
    "            column_embedding = model.encode(column_cleaned, convert_to_tensor=True)\n",
    "\n",
    "            # Compute cosine similarity\n",
    "            similarity_score = util.pytorch_cos_sim(\n",
    "                model.encode(' '.join(question_tokens), convert_to_tensor=True),\n",
    "                column_embedding\n",
    "            ).item()\n",
    "\n",
    "            # Store the similarity score with the original column name\n",
    "            column_similarities[f'{table_name}.{column}'] = similarity_score\n",
    "\n",
    "    # Sort the column similarities by descending similarity score\n",
    "    sorted_similarities = sorted(column_similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return sorted_similarities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "563ad301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30940142273902893\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L12-v2')\n",
    "similarity_score = util.pytorch_cos_sim(\n",
    "    model.encode(\"what is id with name jui and age less than 25\", convert_to_tensor=True),\n",
    "    model.encode(\"name\", convert_to_tensor=True)\n",
    ").item()\n",
    "\n",
    "print(similarity_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b8dc1a",
   "metadata": {},
   "source": [
    "### Filter the table based on the similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e5b7218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_columns(table_info, similarities, threshold):\n",
    "    # Create a new table_info dictionary to store filtered columns\n",
    "    filtered_table_info = {}\n",
    "\n",
    "    for table_name, columns in table_info.items():\n",
    "        filtered_columns = []\n",
    "        for column, similarity in similarities:\n",
    "            # Check if the column belongs to the current table\n",
    "            if column.startswith(table_name):\n",
    "                # Keep the column if similarity is above the threshold\n",
    "                if similarity >= threshold:\n",
    "                    filtered_columns.append(column)\n",
    "\n",
    "        # Only add the table to the filtered_table_info if it has at least one matching column\n",
    "        if filtered_columns:\n",
    "            filtered_table_info[table_name] = [col.split('.')[-1] for col in filtered_columns]\n",
    "\n",
    "    return filtered_table_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5e446a",
   "metadata": {},
   "source": [
    "### Test the two functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85b538b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_inventory.Product ID: 0.6935524344444275\n",
      "customer_orders.Product ID: 0.6935524344444275\n",
      "supplier_info.Product ID: 0.6935524344444275\n",
      "product_inventory.Price: 0.601889431476593\n",
      "supplier_info.Price: 0.601889431476593\n",
      "customer_orders.Order ID: 0.5161583423614502\n",
      "supplier_info.Supplier ID: 0.47025567293167114\n",
      "product_inventory.Product Name: 0.4453805088996887\n",
      "product_inventory.Quantity Available: 0.39232760667800903\n",
      "employee_info.Employee ID: 0.36830848455429077\n",
      "customer_orders.Customer Name: 0.34300094842910767\n",
      "customer_orders.Quantity Ordered: 0.3100193738937378\n",
      "supplier_info.Supplier Name: 0.23508597910404205\n",
      "customer_orders.Order Date: 0.1878075897693634\n",
      "employee_info.Department: 0.18518131971359253\n",
      "supplier_info.Availability: 0.18446308374404907\n",
      "employee_info.First Name: 0.16425180435180664\n",
      "employee_info.Salary: 0.1637563407421112\n",
      "employee_info.Last Name: 0.1349141150712967\n",
      "product_inventory.Category: 0.11724652349948883\n",
      "\n",
      "Filtered table info:  {'product_inventory': ['Product ID', 'Price'], 'customer_orders': ['Product ID', 'Order ID'], 'supplier_info': ['Product ID', 'Price']}\n"
     ]
    }
   ],
   "source": [
    "# Example table information with special characters and spaces\n",
    "table_info = {\n",
    "    'product_inventory': ['Product ID', 'Product Name', 'Category', 'Price', 'Quantity Available'],\n",
    "    'employee_info': ['Employee ID', 'First Name', 'Last Name', 'Department', 'Salary'],\n",
    "    'customer_orders': ['Order ID', 'Customer Name', 'Product ID', 'Quantity Ordered', 'Order Date'],\n",
    "    'supplier_info': ['Supplier ID', 'Supplier Name', 'Product ID', 'Price', 'Availability'],\n",
    "}\n",
    "\n",
    "# Example question \n",
    "question = \"What is the price of Product ID 12345?\"\n",
    "\n",
    "# Compute similarities for the question\n",
    "similarities = compute_similarity(question, table_info)\n",
    "\n",
    "for column, similarity in similarities:\n",
    "    print(f'{column}: {similarity}')\n",
    "    \n",
    "# Set the threshold for filtering columns\n",
    "threshold = 0.5\n",
    "\n",
    "# Filter columns by threshold and print the filtered table_info\n",
    "filtered_table_info = filter_columns(table_info, similarities, threshold)\n",
    "print('\\nFiltered table info: ', filtered_table_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fe10b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"juierror/flan-t5-text2sql-with-schema-v2\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"juierror/flan-t5-text2sql-with-schema-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "198f3626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('people_age.age', 0.5091162323951721), ('people_age.people_id', 0.27685049176216125), ('people_name.name', 0.17837558686733246), ('people_name.id', 0.0970044806599617)]\n",
      "Filtered table info put to the prompt:  {'people_age': ['age']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/namtrinh/.local/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:377: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `10` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT count(*) FROM people_age WHERE name = 'jui' AND age < 25\n",
      "[('people_name.age', 0.4023008644580841), ('people_name.id', 0.32995232939720154), ('people_name.name', 0.2714892625808716)]\n",
      "Filtered table info put to the prompt:  {'people_name': ['age']}\n",
      "SELECT id FROM people_name WHERE name = 'jui' AND age < 25\n"
     ]
    }
   ],
   "source": [
    "def get_prompt(tables, question):\n",
    "    prompt = f\"\"\"convert question and table into SQL query. tables: {tables}. question: {question}\"\"\"\n",
    "    return prompt\n",
    "\n",
    "def prepare_input(question: str, tables: Dict[str, List[str]]):\n",
    "    tables = [f\"\"\"{table_name}({\",\".join(tables[table_name])})\"\"\" for table_name in tables]\n",
    "    tables = \", \".join(tables)\n",
    "    prompt = get_prompt(tables, question)\n",
    "    input_ids = tokenizer(prompt, max_length=512, return_tensors=\"pt\").input_ids\n",
    "    return input_ids\n",
    "\n",
    "def inference(question: str, tables: Dict[str, List[str]]) -> str:\n",
    "    similarities = compute_similarity(question, tables)\n",
    "    filtered_table_info = filter_columns(tables, similarities, threshold=0.4)\n",
    "    print(similarities)\n",
    "    print('Filtered table info put to the prompt: ', str(filtered_table_info))\n",
    "    \n",
    "    input_data = prepare_input(question=question, tables=filtered_table_info)\n",
    "    input_data = input_data.to(model.device)\n",
    "    outputs = model.generate(inputs=input_data, num_beams=10, top_k=10, max_length=512)\n",
    "    result = tokenizer.decode(token_ids=outputs[0], skip_special_tokens=True)\n",
    "    return result\n",
    "\n",
    "print(inference(\"how many people with name jui and age less than 25\", {\n",
    "    \"people_name\": [\"id\", \"name\"],\n",
    "    \"people_age\": [\"people_id\", \"age\"]\n",
    "}))\n",
    "\n",
    "print(inference(\"what is id with name jui and age less than 25\", {\n",
    "    \"people_name\": [\"id\", \"name\", \"age\"]\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be963197",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
