{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98b4b87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch transformers accelerate bitsandbytes scipy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62cf80c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Sep 18 18:39:14 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   54C    P8    26W / 350W |   1773MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1826      G   /usr/lib/xorg/Xorg                  9MiB |\n",
      "|    0   N/A  N/A      1873      C   .../khiem_rcirnew/bin/python     1241MiB |\n",
      "|    0   N/A  N/A      1895      G   /usr/bin/gnome-shell               12MiB |\n",
      "|    0   N/A  N/A     15984      C   .../khiem_rcirnew/bin/python      253MiB |\n",
      "|    0   N/A  N/A     19406      C   .../khiem_rcirnew/bin/python      253MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9835d009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.32.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from typing import List\n",
    "import sqlite3\n",
    "import transformers\n",
    "print(transformers.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f98a21d",
   "metadata": {},
   "source": [
    "# Load the model\n",
    "\n",
    "Set parameter load_in_4bit=True for a model size of 12GB, otherwise the model will be too big. \n",
    "If you work on A100 machine, parameter torch_dtype=torch.bfloat16 can be set to True instead.\n",
    "\n",
    "Can read more here: https://huggingface.co/blog/4bit-transformers-bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0da6922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "977f7fbbdc9b426da5127d5f4c09506a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sql_model_name = \"defog/sqlcoder\"\n",
    "sql_tokenizer = AutoTokenizer.from_pretrained(sql_model_name, cache_dir='/mnt/4TBSSD/huawei2023cache/')\n",
    "sql_model = AutoModelForCausalLM.from_pretrained(\n",
    "    sql_model_name,\n",
    "    trust_remote_code=True,\n",
    "    load_in_4bit=True,\n",
    "    device_map=\"auto\",\n",
    "    use_cache=True,\n",
    "    cache_dir='/mnt/4TBSSD/huawei2023cache/'\n",
    ")\n",
    "\n",
    "answer_model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "token = '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'\n",
    "\n",
    "answer_tokenizer = AutoTokenizer.from_pretrained(answer_model_name, token=token, cache_dir='/mnt/4TBSSD/huawei2023cache/')\n",
    "answer_model = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model='openai-gpt',\n",
    "    # torch_dtype=torch.bfloat16,\n",
    "    # device_map=\"auto\",\n",
    "    # token=token\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e668ed70-4cc3-43c4-99b3-9710823201f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sql_query(model, tokenizer, question: str, db_schema: str, tables_hints: List[str]) -> str:\n",
    "    # Implement logic to generate an SQL query based on the question and table hints.\n",
    "    # Replace the \"pass\" with a calling function to LLM\n",
    "    \n",
    "    # Handle the case when table hints are empty or invalid.\n",
    "    if not tables_hints:\n",
    "        # Default behavior: Query all tables\n",
    "        pass\n",
    "    \n",
    "    # Handle the general case\n",
    "    # Example: \"SELECT COUNT(*) FROM customers\"\n",
    "    prompt = generate_sql_query_generation_prompt(question, db_schema)\n",
    "    eos_token_id = tokenizer.convert_tokens_to_ids([\"```\"])[0]\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\") # or to(\"cpu\")\n",
    "    generated_ids = model.generate(\n",
    "        **inputs,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=eos_token_id,\n",
    "        pad_token_id=eos_token_id,\n",
    "        max_new_tokens=400,\n",
    "        do_sample=False,\n",
    "        num_beams=1\n",
    "    )\n",
    "    \n",
    "    outputs = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "    sql_query = outputs[0].split(\"```sql\")[-1].split(\"```\")[0].split(\";\")[0].strip() + \";\"\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    return sql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af3f0b70-536b-4a3f-bc78-e0d67a8a53cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer_with_context(model, tokenizer, question: str, schema: List[str]) -> str:\n",
    "    answer_generation_prompt = generate_answer_generation_prompt(question, schema)\n",
    "    \n",
    "    ### Use the same procedure\n",
    "    # eos_token_id = tokenizer.convert_tokens_to_ids([\"```\"])[0]\n",
    "    # inputs = tokenizer(answer_generation_prompt, return_tensors=\"pt\").to(\"cuda\") # or to(\"cpu\")\n",
    "\n",
    "    answer = model(\n",
    "        answer_generation_prompt,\n",
    "        do_sample=False,\n",
    "        # top_k=10,\n",
    "        num_return_sequences=1,\n",
    "        # eos_token_id=tokenizer.eos_token_id,\n",
    "        # max_length=200,\n",
    "    )\n",
    "\n",
    "    \n",
    "    # for seq in sequences:\n",
    "    #     print(f\"Result: {seq['generated_text']}\")\n",
    "    \n",
    "    # generated_ids = model.generate(\n",
    "    #     **inputs,\n",
    "    #     num_return_sequences=1,\n",
    "    #     eos_token_id=eos_token_id,\n",
    "    #     pad_token_id=eos_token_id,\n",
    "    #     max_new_tokens=400,\n",
    "    #     do_sample=False,\n",
    "    #     num_beams=1\n",
    "    # )\n",
    "    \n",
    "    # answer = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a348fa39",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb0b85e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_QUERY_PROMPT_TEMPLATE = \"\"\"### Instructions:\n",
    "Your task is to convert a question into a SQL query, given a SQLlite database schema.\n",
    "Adhere to these rules:\n",
    "- **Deliberately go through the question and database schema word by word** to appropriately answer the question\n",
    "- **Use Table Aliases** to prevent ambiguity. For example, `SELECT table1.col1, table2.col1 FROM table1 JOIN table2 ON table1.id = table2.id`.\n",
    "- When creating a ratio, always cast the numerator as float\n",
    "### Input:\n",
    "Generate a SQL query that answers the question `{question}`.\n",
    "This query will run on a database whose schema is represented in this string:\n",
    "{db_schema}\n",
    "\n",
    "### Response:\n",
    "Based on your instructions, here is the SQL query I have generated to answer the question `{question}`:\n",
    "```sql\n",
    "\"\"\"\n",
    "\n",
    "ANSWER_GENERATION_PROMPT_TEMPLATE = \"\"\"\n",
    "The data we have: `{data}`\n",
    "The question: `{question}`\n",
    "The answer: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65f1762f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sql_query_generation_prompt(question, db_schema):\n",
    "    return SQL_QUERY_PROMPT_TEMPLATE.format(question=question, db_schema=db_schema)\n",
    "\n",
    "def generate_answer_generation_prompt(question, data):\n",
    "    return ANSWER_GENERATION_PROMPT_TEMPLATE.format(question=question, data=str(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0129143-e9f3-4608-a9d5-27d7f771dd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_sql_execution(sql_response, sql_schema):\n",
    "    results = []\n",
    "    for row in sql_response:\n",
    "        results.append({\n",
    "            k:v for k,v in zip(sql_schema, row)\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0120465",
   "metadata": {},
   "source": [
    "# Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98c883cb-5f94-4663-86f7-47fa79d5fd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_schemas(cursor, table_hints=None):\n",
    "    '''\n",
    "    get the schema information from this database\n",
    "    '''\n",
    "    tableQuery=\"SELECT name FROM sqlite_master WHERE type='table'\"\n",
    "    tableList=cursor.execute(tableQuery).fetchall()\n",
    "    schemas = []\n",
    "    tables = {}\n",
    "    for table in tableList:\n",
    "        tableName=table[0]\n",
    "        columnQuery=\"PRAGMA table_info('%s')\" % tableName\n",
    "        schema=cursor.execute(columnQuery).fetchall()\n",
    "        tables[tableName] = schema\n",
    "    return tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1912fbe7-b6fb-439a-aef0-8ce7cb35b6a8",
   "metadata": {},
   "source": [
    "# Main functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9656c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_fun(database_name: str) -> sqlite3.Connection:\n",
    "    \"\"\"\n",
    "    Connect to an SQLite database and return a connection object.\n",
    "\n",
    "    Parameters:\n",
    "        database_name (str): The name (or path) of the SQLite database file to connect to.\n",
    "\n",
    "    Returns:\n",
    "        sqlite3.Connection or None: A connection object if the connection is successful,\n",
    "        or None if there is an error.\n",
    "\n",
    "    Example usage:\n",
    "        db_name = 'your_database_name.db'\n",
    "        connection = connect_fun(db_name)\n",
    "        \n",
    "        if connection:\n",
    "            print(f\"Connected to {db_name}\")\n",
    "            # You can now use 'connection' to interact with the database.\n",
    "        else:\n",
    "            print(\"Connection failed.\")\n",
    "    \"\"\"\n",
    "    try:\n",
    "        connection = sqlite3.connect(database_name)\n",
    "        return connection\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Error connecting to the database: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def query_fun(question: str, conn: sqlite3.Connection, tables_hints: List[str]=None, debug:bool=False) -> str:\n",
    "    \"\"\"\n",
    "    Generate an answer to a question based on an SQLite database and question context.\n",
    "\n",
    "    Parameters:\n",
    "        question (str): The user's question.\n",
    "        tables_hints (List[str]): List of table names to consider in the query.\n",
    "        conn (sqlite3.Connection): A connection to the SQLite database.\n",
    "\n",
    "    Returns:\n",
    "        str: The answer to the question.\n",
    "\n",
    "    Example usage:\n",
    "        question = \"How many customers are there in the database?\"\n",
    "        table_hints = [\"customers\"]\n",
    "        connection = sqlite3.connect(\"your_database.db\")\n",
    "        answer = query_fun(question, table_hints, connection)\n",
    "        print(answer)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Step 0: Get related tables based on all schemas and table hints\n",
    "        related_schemas = get_schemas(cursor, tables_hints) \n",
    "\n",
    "        if debug:\n",
    "            print(\"Related schemas: \", related_schemas) \n",
    "        \n",
    "        # Step 1: Generate an SQL query based on the question and table hints.\n",
    "        sql_query = generate_sql_query(sql_model, sql_tokenizer, question, related_schemas, tables_hints)\n",
    "\n",
    "        if debug:\n",
    "            print(\"SQL query: \", sql_query)\n",
    "\n",
    "        # Step 2: Execute the SQL query and fetch the results.\n",
    "        response = cursor.execute(sql_query)\n",
    "\n",
    "        # Step 3: Obtain records from response and schema information (column names) from the cursor description.\n",
    "        records = response.fetchall()\n",
    "        reponse_schema = [desc[0] for desc in cursor.description]\n",
    "        sql_response = format_sql_execution(records, reponse_schema)\n",
    "\n",
    "        if debug:\n",
    "            print(\"SQL execution response: \", sql_response)\n",
    "\n",
    "        # Step 4: Process the query result and generate an answer with context using LLM.\n",
    "        answer = generate_answer_with_context(answer_model, answer_tokenizer, question, records)\n",
    "\n",
    "        return sql_query, answer\n",
    "\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"SQLite Error: {e}\")\n",
    "        return \"An error occurred while processing the query.\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"An error occurred.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791ef412",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3bae86-c7ae-4f3e-a263-b0384d89f703",
   "metadata": {},
   "source": [
    "![alt](/mnt/4TBSSD/pmkhoi/huawei-sql/huawei-arena-2023/imgs/chinook-er-diagram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbe602ce-f0c8-4f94-b6bf-1507ef29d3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = connect_fun('/mnt/4TBSSD/pmkhoi/huawei-sql/huawei-arena-2023/sample_db/Chinook_Sqlite.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bae2938e-3afc-4534-97cd-82985e517369",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = connection.cursor()\n",
    "related_schemas = get_schemas(cursor, table_hints=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5760d2ed-92dd-4b00-be85-090e89ad3f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Album': [(0, 'AlbumId', 'INTEGER', 1, None, 1),\n",
       "  (1, 'Title', 'NVARCHAR(160)', 1, None, 0),\n",
       "  (2, 'ArtistId', 'INTEGER', 1, None, 0)],\n",
       " 'Artist': [(0, 'ArtistId', 'INTEGER', 1, None, 1),\n",
       "  (1, 'Name', 'NVARCHAR(120)', 0, None, 0)],\n",
       " 'Customer': [(0, 'CustomerId', 'INTEGER', 1, None, 1),\n",
       "  (1, 'FirstName', 'NVARCHAR(40)', 1, None, 0),\n",
       "  (2, 'LastName', 'NVARCHAR(20)', 1, None, 0),\n",
       "  (3, 'Company', 'NVARCHAR(80)', 0, None, 0),\n",
       "  (4, 'Address', 'NVARCHAR(70)', 0, None, 0),\n",
       "  (5, 'City', 'NVARCHAR(40)', 0, None, 0),\n",
       "  (6, 'State', 'NVARCHAR(40)', 0, None, 0),\n",
       "  (7, 'Country', 'NVARCHAR(40)', 0, None, 0),\n",
       "  (8, 'PostalCode', 'NVARCHAR(10)', 0, None, 0),\n",
       "  (9, 'Phone', 'NVARCHAR(24)', 0, None, 0),\n",
       "  (10, 'Fax', 'NVARCHAR(24)', 0, None, 0),\n",
       "  (11, 'Email', 'NVARCHAR(60)', 1, None, 0),\n",
       "  (12, 'SupportRepId', 'INTEGER', 0, None, 0)],\n",
       " 'Employee': [(0, 'EmployeeId', 'INTEGER', 1, None, 1),\n",
       "  (1, 'LastName', 'NVARCHAR(20)', 1, None, 0),\n",
       "  (2, 'FirstName', 'NVARCHAR(20)', 1, None, 0),\n",
       "  (3, 'Title', 'NVARCHAR(30)', 0, None, 0),\n",
       "  (4, 'ReportsTo', 'INTEGER', 0, None, 0),\n",
       "  (5, 'BirthDate', 'DATETIME', 0, None, 0),\n",
       "  (6, 'HireDate', 'DATETIME', 0, None, 0),\n",
       "  (7, 'Address', 'NVARCHAR(70)', 0, None, 0),\n",
       "  (8, 'City', 'NVARCHAR(40)', 0, None, 0),\n",
       "  (9, 'State', 'NVARCHAR(40)', 0, None, 0),\n",
       "  (10, 'Country', 'NVARCHAR(40)', 0, None, 0),\n",
       "  (11, 'PostalCode', 'NVARCHAR(10)', 0, None, 0),\n",
       "  (12, 'Phone', 'NVARCHAR(24)', 0, None, 0),\n",
       "  (13, 'Fax', 'NVARCHAR(24)', 0, None, 0),\n",
       "  (14, 'Email', 'NVARCHAR(60)', 0, None, 0)],\n",
       " 'Genre': [(0, 'GenreId', 'INTEGER', 1, None, 1),\n",
       "  (1, 'Name', 'NVARCHAR(120)', 0, None, 0)],\n",
       " 'Invoice': [(0, 'InvoiceId', 'INTEGER', 1, None, 1),\n",
       "  (1, 'CustomerId', 'INTEGER', 1, None, 0),\n",
       "  (2, 'InvoiceDate', 'DATETIME', 1, None, 0),\n",
       "  (3, 'BillingAddress', 'NVARCHAR(70)', 0, None, 0),\n",
       "  (4, 'BillingCity', 'NVARCHAR(40)', 0, None, 0),\n",
       "  (5, 'BillingState', 'NVARCHAR(40)', 0, None, 0),\n",
       "  (6, 'BillingCountry', 'NVARCHAR(40)', 0, None, 0),\n",
       "  (7, 'BillingPostalCode', 'NVARCHAR(10)', 0, None, 0),\n",
       "  (8, 'Total', 'NUMERIC(10,2)', 1, None, 0)],\n",
       " 'InvoiceLine': [(0, 'InvoiceLineId', 'INTEGER', 1, None, 1),\n",
       "  (1, 'InvoiceId', 'INTEGER', 1, None, 0),\n",
       "  (2, 'TrackId', 'INTEGER', 1, None, 0),\n",
       "  (3, 'UnitPrice', 'NUMERIC(10,2)', 1, None, 0),\n",
       "  (4, 'Quantity', 'INTEGER', 1, None, 0)],\n",
       " 'MediaType': [(0, 'MediaTypeId', 'INTEGER', 1, None, 1),\n",
       "  (1, 'Name', 'NVARCHAR(120)', 0, None, 0)],\n",
       " 'Playlist': [(0, 'PlaylistId', 'INTEGER', 1, None, 1),\n",
       "  (1, 'Name', 'NVARCHAR(120)', 0, None, 0)],\n",
       " 'PlaylistTrack': [(0, 'PlaylistId', 'INTEGER', 1, None, 1),\n",
       "  (1, 'TrackId', 'INTEGER', 1, None, 2)],\n",
       " 'Track': [(0, 'TrackId', 'INTEGER', 1, None, 1),\n",
       "  (1, 'Name', 'NVARCHAR(200)', 1, None, 0),\n",
       "  (2, 'AlbumId', 'INTEGER', 0, None, 0),\n",
       "  (3, 'MediaTypeId', 'INTEGER', 1, None, 0),\n",
       "  (4, 'GenreId', 'INTEGER', 0, None, 0),\n",
       "  (5, 'Composer', 'NVARCHAR(220)', 0, None, 0),\n",
       "  (6, 'Milliseconds', 'INTEGER', 1, None, 0),\n",
       "  (7, 'Bytes', 'INTEGER', 0, None, 0),\n",
       "  (8, 'UnitPrice', 'NUMERIC(10,2)', 1, None, 0)]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "038ff1f4-2ce2-45ed-918f-cab59a5797ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    # \"What is the highest sales of three salesman person? Give me the salesperson's name and his or her total sales\",\n",
    "    # \"In 1981 which team picked overall 148?\"\n",
    "\n",
    "    \"Get me the name of all the tracks\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "139cdf9c-99ab-4115-9866-3c8013059c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The size of tensor a (35950) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pmkhoi/.local/lib/python3.11/site-packages/transformers/generation/utils.py:1262: UserWarning: Input length of input_ids is 35950, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sql_command, text_response = query_fun(\n",
    "    question=questions[0],\n",
    "    conn=connection\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b47039c6-097b-4daa-949a-9a19c447d69e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sql_command' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msql_command\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sql_command' is not defined"
     ]
    }
   ],
   "source": [
    "sql_command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4530a2-a403-4d32-a5b5-5aa23e8320ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huawei2023",
   "language": "python",
   "name": "huawei2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
